{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AmadeusChallenge.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ibarrond/Amadeus/blob/master/AmadeusChallenge.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "H26TfTmY0VuU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "cf596f61-9d99-4cf4-84c7-4a1a40535f68"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              " <div style=\"font-variant: small-caps; \n",
              "     font-weight: normal; \n",
              "     font-size: 30px; \n",
              "     text-align: center; \n",
              "     padding: 15px; \n",
              "     margin: 10px;\">\n",
              " Amadeus Challenge for Data Scientists\n",
              " </div> \n",
              "\n",
              " <div style=\"font-variant: small-caps; \n",
              "     font-weight: normal; \n",
              "     font-size: 20px; \n",
              "     text-align: center; \n",
              "     padding: 15px;\">\n",
              " On bookings and searches\n",
              " </div> \n",
              "\n",
              " <div style=\" float:right; \n",
              "     font-size: 12px; \n",
              "     line-height: 12px; \n",
              " padding: 10px 15px 8px;\">\n",
              " Alberto IBARRONDO\n",
              " </div> \n",
              "\n",
              " <div style=\" display: inline-block;\n",
              "     font-family: 'Lato',\n",
              "     sans-serif;\n",
              "     font-size: 12px;\n",
              "     font-weight: bold;\n",
              "     line-height: 12px;\n",
              "     letter-spacing: 1px;\n",
              "     padding: 10px 15px 8px;\">\n",
              " 10/10/2018\n",
              " </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "xuOqipds1vEW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook serves as solution to a challenge for a Data Scientist position in Amadeus. [Data files](https://amadeus.app.box.com/s/285ek69o3e79h2plbkicwj3uiqxbl68n) are not provided, since these files are quite large.\n",
        "\n",
        "View this notebook in http://nbviewer.jupyter.org/github/ibarrond/Amadeus/blob/master/AmadeusChallenge.ipynb\n",
        "\n",
        "Original code can be found in https://github.com/ibarrond/Amadeus"
      ]
    },
    {
      "metadata": {
        "id": "UU7js348l2gw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Set Up the Environment and Load the Data\n",
        "This environment, as part of a Linux Virtual Machine, offers Python3 with GPU acceleration and 12 GB of RAM. The RAM size makes it possible to handle the size of the two files provided for this challenge in memory:\n",
        "- `booking.csv` - 4GB\n",
        "- `searches.csv` - 3.4GB"
      ]
    },
    {
      "metadata": {
        "id": "-vdS1Z_fzPwr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.1 Obtaining the Data\n",
        "In order to import the data we upload the files to a Google Drive folder , then mount our Drive folder in the VM (based on [this tutorial](https://colab.research.google.com/notebooks/io.ipynb)) and finally access the files:"
      ]
    },
    {
      "metadata": {
        "id": "o6nvyH4YmugE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d519d2b-72c9-42fd-cd1d-c08caee49077"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UD6gABOLogr7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We check that the files are there:"
      ]
    },
    {
      "metadata": {
        "id": "fOG_DH_Jnc3G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls -la 'gdrive/My Drive/Colab Notebooks/Amadeus'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U9gGGVPGwe_y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We store the path to each of the data files\n",
        "bookings_file = 'gdrive/My Drive/Colab Notebooks/Amadeus/bookings.csv'\n",
        "searches_file = 'gdrive/My Drive/Colab Notebooks/Amadeus/searches.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QWrj3j83w6CY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### # FIRST EXERCISE: count the number of lines in Python for each file_\n",
        "After a quick searck online, this [source](https://stackoverflow.com/questions/16108526/count-how-many-lines-are-in-a-csv-python) suggested the use of `open()` function to read the number of files:"
      ]
    },
    {
      "metadata": {
        "id": "xmEmanZLw5I8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(bookings_file) as f: bookings_num_lines = sum(1 for line in f)\n",
        "with open(searches_file) as f: searches_num_lines = sum(1 for line in f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8BNEUWHCyi6j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c966680d-5ffd-4235-c7ce-c9849ed8823c"
      },
      "cell_type": "code",
      "source": [
        "bookings_num_lines"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000011"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "pwDbd147ynQ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dac13ba1-ec9e-48d8-f37b-958ed0f87a9d"
      },
      "cell_type": "code",
      "source": [
        "searches_num_lines"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20390199"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "N81uLPvex2uf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__*RESULT*__: we counted **10,000,011** lines in the `bookings.csv` file, and **20,390,199** lines in the `searches.csv` file. Later on we discover that the first line contains the column names."
      ]
    },
    {
      "metadata": {
        "id": "YFxWjnnco3i_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.2 Importing the Bookings Data\n",
        "Now that the files are there, we import them to our IPython session using **Pandas**. Indeed, we will use Pandas for most of our data management."
      ]
    },
    {
      "metadata": {
        "id": "8DUecEPCpOi4",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CS7Ci48pzrPl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Before importing the whole csv file, we'll first have a look at the data structure by examining the first few lines of the file:"
      ]
    },
    {
      "metadata": {
        "id": "4emLR722tXOY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "aa3e417b-3061-433f-ae9d-865a8531e37a"
      },
      "cell_type": "code",
      "source": [
        "bookings = pd.read_csv(bookings_file, nrows=5)\n",
        "bookings.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>act_date           ^source^pos_ctry^pos_iata^pos_oid  ^rloc          ^cre_date           ^duration^distance^dep_port^dep_city^dep_ctry^arr_port^arr_city^arr_ctry^lst_port^lst_city^lst_ctry^brd_port^brd_city^brd_ctry^off_port^off_city^off_ctry^mkt_port^mkt_city^mkt_ctry^intl^route          ^carrier^bkg_class^cab_class^brd_time           ^off_time           ^pax^year^month^oid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-03-05 00:00:00^1A    ^DE      ^a68dd7ae95...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-03-26 00:00:00^1A    ^US      ^e612b9eeee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-03-26 00:00:00^1A    ^US      ^e612b9eeee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-03-26 00:00:00^1A    ^AU      ^0f984b3bb6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-03-26 00:00:00^1A    ^AU      ^0f984b3bb6...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  act_date           ^source^pos_ctry^pos_iata^pos_oid  ^rloc          ^cre_date           ^duration^distance^dep_port^dep_city^dep_ctry^arr_port^arr_city^arr_ctry^lst_port^lst_city^lst_ctry^brd_port^brd_city^brd_ctry^off_port^off_city^off_ctry^mkt_port^mkt_city^mkt_ctry^intl^route          ^carrier^bkg_class^cab_class^brd_time           ^off_time           ^pax^year^month^oid      \n",
              "0  2013-03-05 00:00:00^1A    ^DE      ^a68dd7ae95...                                                                                                                                                                                                                                                                                                                                             \n",
              "1  2013-03-26 00:00:00^1A    ^US      ^e612b9eeee...                                                                                                                                                                                                                                                                                                                                             \n",
              "2  2013-03-26 00:00:00^1A    ^US      ^e612b9eeee...                                                                                                                                                                                                                                                                                                                                             \n",
              "3  2013-03-26 00:00:00^1A    ^AU      ^0f984b3bb6...                                                                                                                                                                                                                                                                                                                                             \n",
              "4  2013-03-26 00:00:00^1A    ^AU      ^0f984b3bb6...                                                                                                                                                                                                                                                                                                                                             "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "3Db5FzVWz-mN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Clearly the symbol '^' is being used as separator. With this in mind, we load the data correctly:"
      ]
    },
    {
      "metadata": {
        "id": "LRRp7lyL0Ske",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "61f6953a-8f4e-4baf-ace6-9e5402c113ad"
      },
      "cell_type": "code",
      "source": [
        "bookings = pd.read_csv(bookings_file, sep='^', nrows=5)\n",
        "bookings.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>act_date</th>\n",
              "      <th>source</th>\n",
              "      <th>pos_ctry</th>\n",
              "      <th>pos_iata</th>\n",
              "      <th>pos_oid</th>\n",
              "      <th>rloc</th>\n",
              "      <th>cre_date</th>\n",
              "      <th>duration</th>\n",
              "      <th>distance</th>\n",
              "      <th>dep_port</th>\n",
              "      <th>...</th>\n",
              "      <th>route</th>\n",
              "      <th>carrier</th>\n",
              "      <th>bkg_class</th>\n",
              "      <th>cab_class</th>\n",
              "      <th>brd_time</th>\n",
              "      <th>off_time</th>\n",
              "      <th>pax</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>oid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-03-05 00:00:00</td>\n",
              "      <td>1A</td>\n",
              "      <td>DE</td>\n",
              "      <td>a68dd7ae953c8acfb187a1af2dcbe123</td>\n",
              "      <td>1a11ae49fcbf545fd2afc1a24d88d2b7</td>\n",
              "      <td>ea65900e72d71f4626378e2ebd298267</td>\n",
              "      <td>2013-02-22 00:00:00</td>\n",
              "      <td>1708</td>\n",
              "      <td>0</td>\n",
              "      <td>ZRH</td>\n",
              "      <td>...</td>\n",
              "      <td>LHRZRH</td>\n",
              "      <td>VI</td>\n",
              "      <td>T</td>\n",
              "      <td>Y</td>\n",
              "      <td>2013-03-07 08:50:00</td>\n",
              "      <td>2013-03-07 11:33:37</td>\n",
              "      <td>-1</td>\n",
              "      <td>2013</td>\n",
              "      <td>3</td>\n",
              "      <td>NULL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-03-26 00:00:00</td>\n",
              "      <td>1A</td>\n",
              "      <td>US</td>\n",
              "      <td>e612b9eeeee6f17f42d9b0d3b79e75ca</td>\n",
              "      <td>7437560d8f276d6d05eeb806d9e7edee</td>\n",
              "      <td>737295a86982c941f1c2da9a46a14043</td>\n",
              "      <td>2013-03-26 00:00:00</td>\n",
              "      <td>135270</td>\n",
              "      <td>0</td>\n",
              "      <td>SAL</td>\n",
              "      <td>...</td>\n",
              "      <td>SALATLCLT</td>\n",
              "      <td>NV</td>\n",
              "      <td>L</td>\n",
              "      <td>Y</td>\n",
              "      <td>2013-04-12 13:04:00</td>\n",
              "      <td>2013-04-12 22:05:40</td>\n",
              "      <td>1</td>\n",
              "      <td>2013</td>\n",
              "      <td>3</td>\n",
              "      <td>NULL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-03-26 00:00:00</td>\n",
              "      <td>1A</td>\n",
              "      <td>US</td>\n",
              "      <td>e612b9eeeee6f17f42d9b0d3b79e75ca</td>\n",
              "      <td>7437560d8f276d6d05eeb806d9e7edee</td>\n",
              "      <td>737295a86982c941f1c2da9a46a14043</td>\n",
              "      <td>2013-03-26 00:00:00</td>\n",
              "      <td>135270</td>\n",
              "      <td>0</td>\n",
              "      <td>SAL</td>\n",
              "      <td>...</td>\n",
              "      <td>CLTATLSAL</td>\n",
              "      <td>NV</td>\n",
              "      <td>U</td>\n",
              "      <td>Y</td>\n",
              "      <td>2013-07-15 07:00:00</td>\n",
              "      <td>2013-07-15 11:34:51</td>\n",
              "      <td>1</td>\n",
              "      <td>2013</td>\n",
              "      <td>3</td>\n",
              "      <td>NULL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-03-26 00:00:00</td>\n",
              "      <td>1A</td>\n",
              "      <td>AU</td>\n",
              "      <td>0f984b3bb6bd06661c95529bbd6193bc</td>\n",
              "      <td>36472c6dbaf7afec9136ac40364e2794</td>\n",
              "      <td>5ecf00fdcbcec761c43dc7285253d0c1</td>\n",
              "      <td>2013-03-26 00:00:00</td>\n",
              "      <td>30885</td>\n",
              "      <td>0</td>\n",
              "      <td>AKL</td>\n",
              "      <td>...</td>\n",
              "      <td>AKLHKGSVO</td>\n",
              "      <td>XK</td>\n",
              "      <td>G</td>\n",
              "      <td>Y</td>\n",
              "      <td>2013-04-24 23:59:00</td>\n",
              "      <td>2013-04-25 16:06:31</td>\n",
              "      <td>1</td>\n",
              "      <td>2013</td>\n",
              "      <td>3</td>\n",
              "      <td>SYDA82546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-03-26 00:00:00</td>\n",
              "      <td>1A</td>\n",
              "      <td>AU</td>\n",
              "      <td>0f984b3bb6bd06661c95529bbd6193bc</td>\n",
              "      <td>36472c6dbaf7afec9136ac40364e2794</td>\n",
              "      <td>5ecf00fdcbcec761c43dc7285253d0c1</td>\n",
              "      <td>2013-03-26 00:00:00</td>\n",
              "      <td>30885</td>\n",
              "      <td>0</td>\n",
              "      <td>AKL</td>\n",
              "      <td>...</td>\n",
              "      <td>SVOHKGAKL</td>\n",
              "      <td>XK</td>\n",
              "      <td>G</td>\n",
              "      <td>Y</td>\n",
              "      <td>2013-05-14 20:15:00</td>\n",
              "      <td>2013-05-16 10:44:50</td>\n",
              "      <td>1</td>\n",
              "      <td>2013</td>\n",
              "      <td>3</td>\n",
              "      <td>SYDA82546</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 38 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   act_date             source  pos_ctry                          pos_iata  \\\n",
              "0  2013-03-05 00:00:00  1A      DE        a68dd7ae953c8acfb187a1af2dcbe123   \n",
              "1  2013-03-26 00:00:00  1A      US        e612b9eeeee6f17f42d9b0d3b79e75ca   \n",
              "2  2013-03-26 00:00:00  1A      US        e612b9eeeee6f17f42d9b0d3b79e75ca   \n",
              "3  2013-03-26 00:00:00  1A      AU        0f984b3bb6bd06661c95529bbd6193bc   \n",
              "4  2013-03-26 00:00:00  1A      AU        0f984b3bb6bd06661c95529bbd6193bc   \n",
              "\n",
              "                          pos_oid                      rloc            \\\n",
              "0  1a11ae49fcbf545fd2afc1a24d88d2b7  ea65900e72d71f4626378e2ebd298267   \n",
              "1  7437560d8f276d6d05eeb806d9e7edee  737295a86982c941f1c2da9a46a14043   \n",
              "2  7437560d8f276d6d05eeb806d9e7edee  737295a86982c941f1c2da9a46a14043   \n",
              "3  36472c6dbaf7afec9136ac40364e2794  5ecf00fdcbcec761c43dc7285253d0c1   \n",
              "4  36472c6dbaf7afec9136ac40364e2794  5ecf00fdcbcec761c43dc7285253d0c1   \n",
              "\n",
              "   cre_date             duration  distance  dep_port    ...      \\\n",
              "0  2013-02-22 00:00:00      1708         0  ZRH         ...       \n",
              "1  2013-03-26 00:00:00    135270         0  SAL         ...       \n",
              "2  2013-03-26 00:00:00    135270         0  SAL         ...       \n",
              "3  2013-03-26 00:00:00     30885         0  AKL         ...       \n",
              "4  2013-03-26 00:00:00     30885         0  AKL         ...       \n",
              "\n",
              "   route           carrier  bkg_class  cab_class  brd_time             \\\n",
              "0  LHRZRH               VI  T          Y          2013-03-07 08:50:00   \n",
              "1  SALATLCLT            NV  L          Y          2013-04-12 13:04:00   \n",
              "2  CLTATLSAL            NV  U          Y          2013-07-15 07:00:00   \n",
              "3  AKLHKGSVO            XK  G          Y          2013-04-24 23:59:00   \n",
              "4  SVOHKGAKL            XK  G          Y          2013-05-14 20:15:00   \n",
              "\n",
              "   off_time            pax  year month  oid        \n",
              "0  2013-03-07 11:33:37  -1  2013     3  NULL       \n",
              "1  2013-04-12 22:05:40   1  2013     3  NULL       \n",
              "2  2013-07-15 11:34:51   1  2013     3  NULL       \n",
              "3  2013-04-25 16:06:31   1  2013     3  SYDA82546  \n",
              "4  2013-05-16 10:44:50   1  2013     3  SYDA82546  \n",
              "\n",
              "[5 rows x 38 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "oPRIRNqFAdLn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We finally load all the `bookings.csv` data correctly. For the second exercise we will only need the columns `pax`, and `arr_port`, thus we only import these:"
      ]
    },
    {
      "metadata": {
        "id": "uOLJ94WPAlEh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bookings = pd.read_csv(bookings_file, usecols=['arr_port', 'pax'], sep='^')\n",
        "bookings.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NETkG7krrUM2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. SECOND EXERCISE: Top 10 arrival airports in the world in 2013"
      ]
    },
    {
      "metadata": {
        "id": "Af8qqKtRskHa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "IN order to accumulate the number of petitions, we should first check for empty data:"
      ]
    },
    {
      "metadata": {
        "id": "ZvBBTl4wp1pt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bookings.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BaFfo0_rs10J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Looks like there is one empty value in the pax column. We will find it and remove it from our dataframe:"
      ]
    },
    {
      "metadata": {
        "id": "J3W-_fdGq6i7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bookings[bookings.isnull().any(axis=1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bQwbAqxKtl15",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bookings = bookings.drop(index=5000007)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CST9d18nuT5g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can launch our query to the dataframe. It is composed of:\n",
        "1. Aggregation by `arr_port`: We will aggregate the destination airport using `groupby(['arr_port'])`.\n",
        "2. Accumulating the number of passengers: sum the pax, simply using `sum()`,\n",
        "3. Obtaining the top 10 by sorting via `.sort_values(by=['pax'], ascending=False)` and extracting the top 10 with `head(10)`."
      ]
    },
    {
      "metadata": {
        "id": "RnUbdFohtQgr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "top10_arr_port = bookings.groupby(['arr_port']).sum().sort_values(by=['pax'], ascending=False).head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zSGW9PBhwfId",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__*RESULT*__: The top 10 airports, including the number of passengers (pax column) are: "
      ]
    },
    {
      "metadata": {
        "id": "WNHiqEe4wsYH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "top10_arr_port"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zWlNzHLgwuTn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__*BONUS*__: we can also obtain the name of the airports. We will use GeoBases for that:"
      ]
    },
    {
      "metadata": {
        "id": "_fdJ3GI13FfQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install GeoBases3K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uqNu2lWj3y6c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from GeoBases import GeoBase\n",
        "geo_a = GeoBase(data='airports')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YjPpoifi73Oo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can search on the airport data using `geo_a.get(x, field='name')`. However, we noticed before that the IATA codes have trailing spaces. We will correct that before anything else. Then we apply the GeoBases get function to the indexes of our dataframe. We can also obtain the city code:"
      ]
    },
    {
      "metadata": {
        "id": "TqyJIlpY48IG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "top10_arr_port.index        = top10_arr_port.index.str.strip()\n",
        "top10_arr_port['port_name'] = top10_arr_port.index.map(lambda x: geo_a.get(x, field='name'))\n",
        "top10_arr_port['city']      = top10_arr_port.index.map(lambda x: geo_a.get(x, field='city_code'))\n",
        "top10_arr_port"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2hj5rKVaBl5I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. THIRD EXERCISE: plot monthly number of searches for flights arriving at Malaga, Madrid or Barcelona"
      ]
    },
    {
      "metadata": {
        "id": "EjkLQbp-B1ow",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For the arriving airport, we can use the Destination column in the searches file. \n",
        "\n",
        "We have to Plot a curve for Málaga, another one for Madrid, and another one for Barcelona, in the same figure. \n",
        "\n",
        "###  3.1 Importing and cleaning the Searches Data\n",
        "\n",
        "Just as with the Bookings data, we need to perform some initial exploratory analysis to correctly import the data."
      ]
    },
    {
      "metadata": {
        "id": "bTz0uYQbC-Ev",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "5878d1bc-20d9-490b-f1f8-9386456b800e"
      },
      "cell_type": "code",
      "source": [
        "searches = pd.read_csv(searches_file, nrows=5)\n",
        "searches.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date^Time^TxnCode^OfficeID^Country^Origin^Destination^RoundTrip^NbSegments^Seg1Departure^Seg1Arrival^Seg1Date^Seg1Carrier^Seg1BookingCode^Seg2Departure^Seg2Arrival^Seg2Date^Seg2Carrier^Seg2BookingCode^Seg3Departure^Seg3Arrival^Seg3Date^Seg3Carrier^Seg3BookingCode^Seg4Departure^Seg4Arrival^Seg4Date^Seg4Carrier^Seg4BookingCode^Seg5Departure^Seg5Arrival^Seg5Date^Seg5Carrier^Seg5BookingCode^Seg6Departure^Seg6Arrival^Seg6Date^Seg6Carrier^Seg6BookingCode^From^IsPublishedForNeg^IsFromInternet^IsFromVista^TerminalID^InternetOffice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-01-01^20:25:57^MPT^624d8c3ac0b3a7ca03e3c1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-01-01^10:15:33^MPT^b0af35b31588dc4ab06d5c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-01-01^18:04:49^MPT^3561a60621de06ab1badc8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-01-01^17:42:40^FXP^1864e5e8013d9414150e91...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-01-01^17:48:29^MPT^1ec336348f44207d2e0027...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Date^Time^TxnCode^OfficeID^Country^Origin^Destination^RoundTrip^NbSegments^Seg1Departure^Seg1Arrival^Seg1Date^Seg1Carrier^Seg1BookingCode^Seg2Departure^Seg2Arrival^Seg2Date^Seg2Carrier^Seg2BookingCode^Seg3Departure^Seg3Arrival^Seg3Date^Seg3Carrier^Seg3BookingCode^Seg4Departure^Seg4Arrival^Seg4Date^Seg4Carrier^Seg4BookingCode^Seg5Departure^Seg5Arrival^Seg5Date^Seg5Carrier^Seg5BookingCode^Seg6Departure^Seg6Arrival^Seg6Date^Seg6Carrier^Seg6BookingCode^From^IsPublishedForNeg^IsFromInternet^IsFromVista^TerminalID^InternetOffice\n",
              "0  2013-01-01^20:25:57^MPT^624d8c3ac0b3a7ca03e3c1...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
              "1  2013-01-01^10:15:33^MPT^b0af35b31588dc4ab06d5c...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
              "2  2013-01-01^18:04:49^MPT^3561a60621de06ab1badc8...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
              "3  2013-01-01^17:42:40^FXP^1864e5e8013d9414150e91...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
              "4  2013-01-01^17:48:29^MPT^1ec336348f44207d2e0027...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "0oJVAbl-DUHi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Yet again, the delimiter seems to be '^'. "
      ]
    },
    {
      "metadata": {
        "id": "y3LP13p4DaHS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "6e0a6a91-d14b-4064-8872-c0c7af504abf"
      },
      "cell_type": "code",
      "source": [
        "searches = pd.read_csv(searches_file, delimiter='^', nrows=5)\n",
        "searches.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>TxnCode</th>\n",
              "      <th>OfficeID</th>\n",
              "      <th>Country</th>\n",
              "      <th>Origin</th>\n",
              "      <th>Destination</th>\n",
              "      <th>RoundTrip</th>\n",
              "      <th>NbSegments</th>\n",
              "      <th>Seg1Departure</th>\n",
              "      <th>...</th>\n",
              "      <th>Seg6Arrival</th>\n",
              "      <th>Seg6Date</th>\n",
              "      <th>Seg6Carrier</th>\n",
              "      <th>Seg6BookingCode</th>\n",
              "      <th>From</th>\n",
              "      <th>IsPublishedForNeg</th>\n",
              "      <th>IsFromInternet</th>\n",
              "      <th>IsFromVista</th>\n",
              "      <th>TerminalID</th>\n",
              "      <th>InternetOffice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>20:25:57</td>\n",
              "      <td>MPT</td>\n",
              "      <td>624d8c3ac0b3a7ca03e3c167e0f48327</td>\n",
              "      <td>DE</td>\n",
              "      <td>TXL</td>\n",
              "      <td>AUH</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>TXL</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1ASIWS</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
              "      <td>FRA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>10:15:33</td>\n",
              "      <td>MPT</td>\n",
              "      <td>b0af35b31588dc4ab06d5cf2986e8e02</td>\n",
              "      <td>MD</td>\n",
              "      <td>ATH</td>\n",
              "      <td>MIL</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>ATH</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1ASIWS</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
              "      <td>KIV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>18:04:49</td>\n",
              "      <td>MPT</td>\n",
              "      <td>3561a60621de06ab1badc8ca55699ef3</td>\n",
              "      <td>US</td>\n",
              "      <td>ICT</td>\n",
              "      <td>SFO</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>ICT</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1ASIWS</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
              "      <td>NYC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>17:42:40</td>\n",
              "      <td>FXP</td>\n",
              "      <td>1864e5e8013d9414150e91d26b6a558b</td>\n",
              "      <td>SE</td>\n",
              "      <td>RNB</td>\n",
              "      <td>ARN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>RNB</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1ASI</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
              "      <td>STO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>17:48:29</td>\n",
              "      <td>MPT</td>\n",
              "      <td>1ec336348f44207d2e0027dc3a68c118</td>\n",
              "      <td>NO</td>\n",
              "      <td>OSL</td>\n",
              "      <td>MAD</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>OSL</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1ASIWS</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
              "      <td>OSL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 45 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date      Time TxnCode                          OfficeID Country  \\\n",
              "0  2013-01-01  20:25:57     MPT  624d8c3ac0b3a7ca03e3c167e0f48327      DE   \n",
              "1  2013-01-01  10:15:33     MPT  b0af35b31588dc4ab06d5cf2986e8e02      MD   \n",
              "2  2013-01-01  18:04:49     MPT  3561a60621de06ab1badc8ca55699ef3      US   \n",
              "3  2013-01-01  17:42:40     FXP  1864e5e8013d9414150e91d26b6a558b      SE   \n",
              "4  2013-01-01  17:48:29     MPT  1ec336348f44207d2e0027dc3a68c118      NO   \n",
              "\n",
              "  Origin Destination  RoundTrip  NbSegments Seg1Departure       ...        \\\n",
              "0    TXL         AUH          1           2           TXL       ...         \n",
              "1    ATH         MIL          0           1           ATH       ...         \n",
              "2    ICT         SFO          1           2           ICT       ...         \n",
              "3    RNB         ARN          0           1           RNB       ...         \n",
              "4    OSL         MAD          1           2           OSL       ...         \n",
              "\n",
              "  Seg6Arrival Seg6Date Seg6Carrier Seg6BookingCode    From IsPublishedForNeg  \\\n",
              "0         NaN      NaN         NaN             NaN  1ASIWS                 0   \n",
              "1         NaN      NaN         NaN             NaN  1ASIWS                 0   \n",
              "2         NaN      NaN         NaN             NaN  1ASIWS                 0   \n",
              "3         NaN      NaN         NaN             NaN    1ASI                 0   \n",
              "4         NaN      NaN         NaN             NaN  1ASIWS                 0   \n",
              "\n",
              "  IsFromInternet IsFromVista                        TerminalID  InternetOffice  \n",
              "0              0           0  d41d8cd98f00b204e9800998ecf8427e             FRA  \n",
              "1              0           0  d41d8cd98f00b204e9800998ecf8427e             KIV  \n",
              "2              0           0  d41d8cd98f00b204e9800998ecf8427e             NYC  \n",
              "3              0           0  d41d8cd98f00b204e9800998ecf8427e             STO  \n",
              "4              0           0  d41d8cd98f00b204e9800998ecf8427e             OSL  \n",
              "\n",
              "[5 rows x 45 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "I4bkkQ3ID5bQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For now we're only interested in the Destination airport and the date. Let's get all the data:"
      ]
    },
    {
      "metadata": {
        "id": "YFFcc-HcD4-o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e6be4abb-64d4-4098-b6e8-0b4156830ca9"
      },
      "cell_type": "code",
      "source": [
        "searches = pd.read_csv(searches_file, delimiter='^', usecols=['Date', 'Destination'])\n",
        "searches.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Destination</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>AUH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>MIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>SFO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>ARN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>MAD</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date Destination\n",
              "0  2013-01-01         AUH\n",
              "1  2013-01-01         MIL\n",
              "2  2013-01-01         SFO\n",
              "3  2013-01-01         ARN\n",
              "4  2013-01-01         MAD"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "loaPy2fOHuWL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Before going any further, we check for empty values that might cause some errors."
      ]
    },
    {
      "metadata": {
        "id": "qRTLNKRfHUXq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "searches.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eCj7s6tiH2lq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Since we have several empty values, we remove them from our dataset:"
      ]
    },
    {
      "metadata": {
        "id": "4mue1wDyHjyB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "searches = searches.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IQNhGHGlIaUl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have  awuick look at the resulting dataset:"
      ]
    },
    {
      "metadata": {
        "id": "7jNym5NdIgD6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "searches.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sc1ahh3yJuFI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our Date column is of type `string`, but turning it into a `datetime` column would allow us to play with time lapses. Let's do so:"
      ]
    },
    {
      "metadata": {
        "id": "BtMb2efhIsAN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "searches.loc[:,'Date'] = pd.to_datetime(searches['Date'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zcCqT6TcIvgA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.2 Solving the exercise"
      ]
    },
    {
      "metadata": {
        "id": "UyNQzHpPEPQk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The codes for Madrid, Barcelona and Malaga are, respectively, **MAD, BCN **& **AGP** (obtained from a quick search online).\n",
        "\n",
        "With our data in place and cleaned, we can extract our information of interest:\n",
        "1. First we filter the data using `.str.contains(city_code)` in the Destination,\n",
        "2. Then we estract the month from the date `.dt.month`,\n",
        "2. Finally we aggregate the data on each month with `.value_counts()` and sort it by month with `.sort_index()`."
      ]
    },
    {
      "metadata": {
        "id": "4aJz-15tExdy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 1. Filter data by the airport name\n",
        "searches_mad = searches[searches['Destination'].str.contains(\"MAD\")]\n",
        "searches_bcn = searches[searches['Destination'].str.contains(\"BCN\")]\n",
        "searches_agp = searches[searches['Destination'].str.contains(\"AGP\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7qdQiDcrNT5O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 2 & 3. Extract month, aggregate and sort\n",
        "monthly_searches_mad = searches_mad['Date'].dt.month.value_counts().sort_index()\n",
        "monthly_searches_bcn = searches_bcn['Date'].dt.month.value_counts().sort_index()\n",
        "monthly_searches_agp = searches_agp['Date'].dt.month.value_counts().sort_index()\n",
        "monthly_searches_mad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wv6dJOk1VQlz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__*RESULT*__ We plot all three series into one single plot using `matplotlib` for plotting and `seaborn` for style:"
      ]
    },
    {
      "metadata": {
        "id": "RTPyHrTeYEVi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Labels: months\n",
        "import calendar\n",
        "labels = list(calendar.month_name[1:])\n",
        "\n",
        "# Combining all dataframes into one\n",
        "monthly_searches = pd.DataFrame([monthly_searches_mad,\n",
        "                                 monthly_searches_bcn,\n",
        "                                 monthly_searches_agp],\n",
        "                                index = ['Madrid','Barcelona', 'Málaga']\n",
        "                               )\n",
        "monthly_searches = monthly_searches.T\n",
        "monthly_searches.index = labels\n",
        "monthly_searches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H_dVD9FNVCTe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "plt.tight_layout()\n",
        "monthly_searches.plot(kind='bar', figsize=[16, 10])\n",
        "plt.legend(loc='best', prop={'size':18})\n",
        "plt.xlabel(\"Month\", fontsize=22, fontstyle='oblique')\n",
        "plt.ylabel(\"Number of searches\", fontsize=22, fontstyle='oblique')\n",
        "plt.xticks(np.arange(12)+0.2, monthly_searches.index, rotation=40, fontsize=15, ha='right')\n",
        "plt.title('Monthly number of searches by arriving airport in 2013', fontsize=26, fontweight='bold')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JYdaVcLihOIH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Bonus exercise: match searches with bookings\n"
      ]
    },
    {
      "metadata": {
        "id": "9W0Jk2CK2-hw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We import the columns from each dataset that will be useful, and we rename `bookings` to match the names in `searches`. Since this matching should be done uniquely (avoid duplicates), we will be performing what in SQL would be called `left join`, this is, keeping the searches table intact while adding the bookings that match.\n",
        "\n",
        "A first approach, just using the searches columns \"Destination\" (\"arr_port\" in bookings)  and \"Origin\" (\"dep_port\" in bookings) to perform the matching generated so many duplicates that the memory would overflow and crash the system.\n",
        "\n",
        "Later on we included also the column \"Date\" (\"act_date\" in bookings) in the matching. The idea behind it is that bookings with a pax>0 (bookings that are not cancellations) have a cre_date equal to the act_date, while bookings with pax<0 (cancellations) have different cre_date and act_date. We just care about bookings with pax>0, not about cancellations. This strategy led us to obtain a merged table with 24,000,000 entries.\n",
        "\n",
        "To narrow it even further, we dedided to additionally include the column \"Seg1Date\", matching it to the \"brd_time\" in bookings, given that the date of the first flight whould match the booking. Despite knowing that one search could generate several bookings (if there are several segments involved), to solve this question we only need to check the first segment; thus, we disregard the rest of the segments.\n",
        "\n",
        "Let's do it then!"
      ]
    },
    {
      "metadata": {
        "id": "CUKdTeav28Nc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.1 Importing and cleaning both bookings and searches\n",
        "First of all we import the desired columns from searches and bookings using the same naming convention and cleaning the labels in the process:"
      ]
    },
    {
      "metadata": {
        "id": "v9M37tAsQs1e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "searches = pd.read_csv(searches_file,\n",
        "                       delimiter= '^',\n",
        "                       usecols=['Date','Origin','Destination', 'Seg1Date'])\n",
        "bookings = pd.read_csv(bookings_file,\n",
        "                       usecols=['cre_date           ',\n",
        "                                'dep_port', 'arr_port',\n",
        "                                'pax',\n",
        "                                'brd_time           '],\n",
        "                       sep='^')\n",
        "bookings = bookings.rename(index=str,\n",
        "                           columns={\"cre_date           \": \"Date\",\n",
        "                                    \"dep_port\": \"Origin\",\n",
        "                                    \"arr_port\": \"Destination\",\n",
        "                                    })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3DJk_Vf15izZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As before, we will drop the empty values:"
      ]
    },
    {
      "metadata": {
        "id": "Ai1b8CM050gt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bookings = bookings.dropna()\n",
        "searches = searches.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g_FrgnmG5nSY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Noticing the white spaces in the Bookings table, we clean them too before merging (otherwise we would get no matches!)"
      ]
    },
    {
      "metadata": {
        "id": "Iz-kfvAwjo1W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bookings.loc[:,'Origin'] = bookings['Origin'].str.strip()\n",
        "bookings.loc[:,'Destination'] = bookings['Destination'].str.strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W8anCi2v2J_5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Since we are treating with dates, we will use the same format for both of them. Hence, we drop the information about hours/minutes/seconds (since that info is not present in the bookings table). In general, we clean all the dates."
      ]
    },
    {
      "metadata": {
        "id": "pee2IppX23Vm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bookings.loc[:,'Date'] = bookings.loc[:,'Date'].str.replace(' 00:00:00','')\n",
        "bookings.loc[:,'Seg1Date'] = bookings.loc[:,'Seg1Date'].str.replace(' [0-9]{2}:[0-9]{2}:[0-9]{2}','')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N76aRAEU-MhH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Before the merge, in order to keep an idea of the ID of both booking and search, we will include their IDs (the row numbers) as a new row in each column:"
      ]
    },
    {
      "metadata": {
        "id": "81GFrUwM-cqC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "searches[\"searches_ID\"] = searches.index\n",
        "bookings[\"booking_ID\"] = bookings.index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ok5OpLof9F2F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The results of these imports and cleaning are two datasets ready to be merged:"
      ]
    },
    {
      "metadata": {
        "id": "Mo0sNVjW9JWR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4e9eae52-c0bf-4595-e96f-1c1ad8f266fe"
      },
      "cell_type": "code",
      "source": [
        "searches.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Origin</th>\n",
              "      <th>Destination</th>\n",
              "      <th>Seg1Date</th>\n",
              "      <th>searches_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>TXL</td>\n",
              "      <td>AUH</td>\n",
              "      <td>2013-01-26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>ATH</td>\n",
              "      <td>MIL</td>\n",
              "      <td>2013-01-04</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>ICT</td>\n",
              "      <td>SFO</td>\n",
              "      <td>2013-08-02</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>RNB</td>\n",
              "      <td>ARN</td>\n",
              "      <td>2013-01-02</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>OSL</td>\n",
              "      <td>MAD</td>\n",
              "      <td>2013-03-22</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date Origin Destination    Seg1Date  searches_ID\n",
              "0  2013-01-01    TXL         AUH  2013-01-26            0\n",
              "1  2013-01-01    ATH         MIL  2013-01-04            1\n",
              "2  2013-01-01    ICT         SFO  2013-08-02            2\n",
              "3  2013-01-01    RNB         ARN  2013-01-02            3\n",
              "4  2013-01-01    OSL         MAD  2013-03-22            4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "RJ4ipvKa_09v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0ae56c4a-eaec-43b5-f394-199d100d37c5"
      },
      "cell_type": "code",
      "source": [
        "bookings.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Origin</th>\n",
              "      <th>Destination</th>\n",
              "      <th>Seg1Date</th>\n",
              "      <th>pax</th>\n",
              "      <th>booking_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-03-05</td>\n",
              "      <td>ZRH</td>\n",
              "      <td>LHR</td>\n",
              "      <td>2013-03-07</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-03-26</td>\n",
              "      <td>SAL</td>\n",
              "      <td>CLT</td>\n",
              "      <td>2013-04-12</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-03-26</td>\n",
              "      <td>SAL</td>\n",
              "      <td>CLT</td>\n",
              "      <td>2013-07-15</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-03-26</td>\n",
              "      <td>AKL</td>\n",
              "      <td>SVO</td>\n",
              "      <td>2013-04-24</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-03-26</td>\n",
              "      <td>AKL</td>\n",
              "      <td>SVO</td>\n",
              "      <td>2013-05-14</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date Origin Destination    Seg1Date  pax booking_ID\n",
              "0  2013-03-05    ZRH         LHR  2013-03-07 -1.0          0\n",
              "1  2013-03-26    SAL         CLT  2013-04-12  1.0          1\n",
              "2  2013-03-26    SAL         CLT  2013-07-15  1.0          2\n",
              "3  2013-03-26    AKL         SVO  2013-04-24  1.0          3\n",
              "4  2013-03-26    AKL         SVO  2013-05-14  1.0          4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "1C7qCNNtAdvJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.2 Merging both tables"
      ]
    },
    {
      "metadata": {
        "id": "t4TlWcsj_L-1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we are finally ready to merge both tables, using the `merge` function from pandas (given that the `join` function uses the column numbers to perform the join). To save up memory (we are kind of running short on that), we use the"
      ]
    },
    {
      "metadata": {
        "id": "3uyKGrp1AxAX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "merged = searches.merge(bookings, how='left', on=['Date', 'Origin', 'Destination', 'Seg1Date'], copy=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ccTYdFdDyVR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "188cd814-94ba-4e5f-87e3-cabb61b24982"
      },
      "cell_type": "code",
      "source": [
        "merged.head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Origin</th>\n",
              "      <th>Destination</th>\n",
              "      <th>Seg1Date</th>\n",
              "      <th>searches_ID</th>\n",
              "      <th>pax</th>\n",
              "      <th>booking_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>TXL</td>\n",
              "      <td>AUH</td>\n",
              "      <td>2013-01-26</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>ATH</td>\n",
              "      <td>MIL</td>\n",
              "      <td>2013-01-04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>ICT</td>\n",
              "      <td>SFO</td>\n",
              "      <td>2013-08-02</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>RNB</td>\n",
              "      <td>ARN</td>\n",
              "      <td>2013-01-02</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>OSL</td>\n",
              "      <td>MAD</td>\n",
              "      <td>2013-03-22</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date Origin Destination    Seg1Date  searches_ID  pax booking_ID\n",
              "0  2013-01-01    TXL         AUH  2013-01-26            0  NaN        NaN\n",
              "1  2013-01-01    ATH         MIL  2013-01-04            1  NaN        NaN\n",
              "2  2013-01-01    ICT         SFO  2013-08-02            2  NaN        NaN\n",
              "3  2013-01-01    RNB         ARN  2013-01-02            3  NaN        NaN\n",
              "4  2013-01-01    OSL         MAD  2013-03-22            4  NaN        NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "iXKbMnGqDvs3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "All the columns where there were no merges will have a NaN in the pax and booking_ID fields. To effectively count the number, we will count non NaN:"
      ]
    },
    {
      "metadata": {
        "id": "q2I9kfPJEHzL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2000
        },
        "outputId": "3520911a-8d2b-4697-ad96-0f45f8fee41f"
      },
      "cell_type": "code",
      "source": [
        "merged.dropna().groupby('searches_ID').count()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Origin</th>\n",
              "      <th>Destination</th>\n",
              "      <th>Seg1Date</th>\n",
              "      <th>pax</th>\n",
              "      <th>booking_ID</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>searches_ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>432</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>741</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>923</th>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1150</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1222</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1841</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1895</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2038</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2172</th>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2173</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2349</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2536</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2722</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2931</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2980</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3217</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3305</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3491</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3618</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3950</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4129</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4303</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4445</th>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4753</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5165</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20365524</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20366179</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20366489</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20367223</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20368495</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20368530</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20369713</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20371048</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20371764</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20374187</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20376936</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20377637</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20377929</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20378001</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20378373</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20378583</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20378797</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20379155</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20379806</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20379853</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20379885</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20380031</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20380113</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20380314</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20381208</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20381287</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20384424</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20387138</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20387516</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20387983</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>37143 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Date  Origin  Destination  Seg1Date  pax  booking_ID\n",
              "searches_ID                                                      \n",
              "303            10      10           10        10   10          10\n",
              "432            10      10           10        10   10          10\n",
              "596            10      10           10        10   10          10\n",
              "741            10      10           10        10   10          10\n",
              "923            30      30           30        30   30          30\n",
              "972            10      10           10        10   10          10\n",
              "1150           10      10           10        10   10          10\n",
              "1222           10      10           10        10   10          10\n",
              "1841           10      10           10        10   10          10\n",
              "1895           10      10           10        10   10          10\n",
              "2014           10      10           10        10   10          10\n",
              "2021           10      10           10        10   10          10\n",
              "2038           10      10           10        10   10          10\n",
              "2172           20      20           20        20   20          20\n",
              "2173           10      10           10        10   10          10\n",
              "2349           10      10           10        10   10          10\n",
              "2536           10      10           10        10   10          10\n",
              "2722           10      10           10        10   10          10\n",
              "2931           10      10           10        10   10          10\n",
              "2980           10      10           10        10   10          10\n",
              "3217           10      10           10        10   10          10\n",
              "3305           10      10           10        10   10          10\n",
              "3491           10      10           10        10   10          10\n",
              "3618           10      10           10        10   10          10\n",
              "3950           10      10           10        10   10          10\n",
              "4129           10      10           10        10   10          10\n",
              "4303           10      10           10        10   10          10\n",
              "4445           20      20           20        20   20          20\n",
              "4753           10      10           10        10   10          10\n",
              "5165           10      10           10        10   10          10\n",
              "...           ...     ...          ...       ...  ...         ...\n",
              "20365524       10      10           10        10   10          10\n",
              "20366179       10      10           10        10   10          10\n",
              "20366489       10      10           10        10   10          10\n",
              "20367223       10      10           10        10   10          10\n",
              "20368495       10      10           10        10   10          10\n",
              "20368530       10      10           10        10   10          10\n",
              "20369713       10      10           10        10   10          10\n",
              "20371048       10      10           10        10   10          10\n",
              "20371764       10      10           10        10   10          10\n",
              "20374187       10      10           10        10   10          10\n",
              "20376936       10      10           10        10   10          10\n",
              "20377637       10      10           10        10   10          10\n",
              "20377929       10      10           10        10   10          10\n",
              "20378001       10      10           10        10   10          10\n",
              "20378373       10      10           10        10   10          10\n",
              "20378583       10      10           10        10   10          10\n",
              "20378797       10      10           10        10   10          10\n",
              "20379155       10      10           10        10   10          10\n",
              "20379806       10      10           10        10   10          10\n",
              "20379853       10      10           10        10   10          10\n",
              "20379885       10      10           10        10   10          10\n",
              "20380031       10      10           10        10   10          10\n",
              "20380113       10      10           10        10   10          10\n",
              "20380314       10      10           10        10   10          10\n",
              "20381208       10      10           10        10   10          10\n",
              "20381287       10      10           10        10   10          10\n",
              "20384424       10      10           10        10   10          10\n",
              "20387138       10      10           10        10   10          10\n",
              "20387516       10      10           10        10   10          10\n",
              "20387983       10      10           10        10   10          10\n",
              "\n",
              "[37143 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "qqSvhgDjEps6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "435k out of 20M, and only 37143 unique searches ended up in some kind of booking, clearly we were too restrictive! We will backtrack and get rid of the Seg1Date."
      ]
    },
    {
      "metadata": {
        "id": "2W-l8Wv5Ef1Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}